{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCkwivecmXn0yRVmlJ5rGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sairamkundalapalli/NLP_Sai-Ram/blob/main/Assignment_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Load data fromkeras.datasets and perform following computational analysis:- [CO3]\n",
        "(a) Preprocessing of the Data\n",
        "\n",
        "(b) Divide data into training and testing data set\n",
        "\n",
        "(c) Build the Gated Recurrent Units (GRU) Model\n",
        "\n",
        "(d) Training the GRU Model\n",
        "\n",
        "(e) Text Generation Using the Trained Model\n",
        "\n",
        " (f)  Evaluate Model’s accuracy"
      ],
      "metadata": {
        "id": "QAGwkjaBiexk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrJS1CggiD9P",
        "outputId": "90253893-2bb4-400d-ad58-1075e7bef44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 297ms/step - accuracy: 0.7275 - loss: 0.5229 - val_accuracy: 0.7928 - val_loss: 0.4603\n",
            "Epoch 2/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 273ms/step - accuracy: 0.8824 - loss: 0.2983 - val_accuracy: 0.8786 - val_loss: 0.3099\n",
            "Epoch 3/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 274ms/step - accuracy: 0.9500 - loss: 0.1439 - val_accuracy: 0.8804 - val_loss: 0.3213\n",
            "Epoch 4/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 276ms/step - accuracy: 0.9779 - loss: 0.0666 - val_accuracy: 0.8554 - val_loss: 0.4017\n",
            "Epoch 5/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 279ms/step - accuracy: 0.9910 - loss: 0.0304 - val_accuracy: 0.8698 - val_loss: 0.4637\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 57ms/step - accuracy: 0.8623 - loss: 0.5064\n",
            "Test accuracy: 0.8633999824523926\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load the IMDB dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=20000)\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "maxlen = 200\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Build the Gated Recurrent Units (GRU) Model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=20000, output_dim=128))\n",
        "model.add(layers.GRU(128))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Training the GRU Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate Model's accuracy\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Compare accuracy of Long sort term memory and Gated recurrent Unit models for text generation using data from tensorflow.keras.datasets. [CO3]"
      ],
      "metadata": {
        "id": "f_7lIDVbmLkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "\n",
        "# Load the IMDB dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "max_len = 200\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# Define the LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(10000, 128))\n",
        "lstm_model.add(LSTM(128))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the LSTM model\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the GRU model\n",
        "gru_model = Sequential()\n",
        "gru_model.add(Embedding(10000, 128))\n",
        "gru_model.add(GRU(128))\n",
        "gru_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the GRU model\n",
        "gru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Train the GRU model\n",
        "gru_model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the models\n",
        "lstm_loss, lstm_accuracy = lstm_model.evaluate(x_test, y_test)\n",
        "gru_loss, gru_accuracy = gru_model.evaluate(x_test, y_test)\n",
        "\n",
        "print('LSTM Accuracy:', lstm_accuracy)\n",
        "print('GRU Accuracy:', gru_accuracy)\n",
        "\n",
        "# Compare the accuracy of the models\n",
        "if lstm_accuracy > gru_accuracy:\n",
        "  print('LSTM model has higher accuracy.')\n",
        "elif gru_accuracy > lstm_accuracy:\n",
        "  print('GRU model has higher accuracy.')\n",
        "else:\n",
        "  print('Both models have similar accuracy.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jukl0uPi5cr",
        "outputId": "0b2e7083-fee0-426c-fd20-b4cec3ff6c1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 473ms/step - accuracy: 0.6837 - loss: 0.5723 - val_accuracy: 0.8252 - val_loss: 0.4094\n",
            "Epoch 2/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 470ms/step - accuracy: 0.8695 - loss: 0.3207 - val_accuracy: 0.8678 - val_loss: 0.3241\n",
            "Epoch 3/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 474ms/step - accuracy: 0.9235 - loss: 0.2003 - val_accuracy: 0.8604 - val_loss: 0.3490\n",
            "Epoch 1/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 504ms/step - accuracy: 0.6645 - loss: 0.5836 - val_accuracy: 0.8144 - val_loss: 0.4097\n",
            "Epoch 2/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 499ms/step - accuracy: 0.8800 - loss: 0.2864 - val_accuracy: 0.8664 - val_loss: 0.3264\n",
            "Epoch 3/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 490ms/step - accuracy: 0.9264 - loss: 0.1968 - val_accuracy: 0.8662 - val_loss: 0.3235\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 103ms/step - accuracy: 0.8585 - loss: 0.3539\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 58ms/step - accuracy: 0.8583 - loss: 0.3378\n",
            "LSTM Accuracy: 0.8605599999427795\n",
            "GRU Accuracy: 0.8618800044059753\n",
            "GRU model has higher accuracy.\n"
          ]
        }
      ]
    }
  ]
}